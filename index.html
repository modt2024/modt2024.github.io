<!DOCTYPE html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Mixture of Diffusion Timesteps for Multimodal Generation</title>
    <style>
        body, td, th, tr, p {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }
        
        h1 {
            font-weight: normal;
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
            margin-bottom: 25px;
            margin-top: 10px;
        }

        h2 {
            font-weight: normal;
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 22px;
            padding-left: 20px;
            margin-top: 0px;
        }
        
        h3 {
            font-weight: normal;
            font-size: 15px;
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            padding-left: 40px;
            text-align: center;
        }
        
        a {
            font-weight: normal;
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px;
            padding-left: 45px;
            margin-top: 0px;
        }
        b1 { 
  font-size: inherit;  /* Inherit font size from parent element */ 
}
        p{
            padding-left: 40px;
        }
        
        .container {
            margin-left: auto;
            margin-right: auto;
            width: 80% /* Fixed width for larger screens */
            height: 960px;
            max-width: 960px;
            padding: 20px;
        }

        .content {
            font-size: 16px; 
        }
        
        .video-pair {
            display: flex;
            justify-content: space-around;
            margin-bottom: 20px;
        }
        
        .video-container {
            width: 100%; 
            max-width: 600px; /* Adjust this to control the maximum size */
            margin: auto; 
            position: relative;
            height: auto; 
            border-radius: 15px;
            overflow: hidden;
            margin-bottom: 0px;
        }
        
        .video {
            width: 100%; 
            height: auto; 
            border-radius: 15px;
            object-fit: contain; 
        }

        .buttons {
            text-align: center;
            padding: 20px;
            margin-top: 10px;
            margin-bottom: 0px;
        }
        
        .button {
            background-color: darkgrey;
            color: white;
            border: none;
            border-radius: 20px;
            padding: 10px 20px;
            text-decoration: none;
            margin: 0 10px;
        }
        
        .button:hover {
            background-color: grey;
        }

        .example-divider {
            border-color: #cccccc; /* Light grey color */
            border-width: 1px; /* Thin line */
            margin-top: 50px; /* Top margin */
            margin-bottom: 50px; /* Bottom margin */
            width: 80%; /* Adjusts the width of the line */
            margin-left: auto; /* Centers the line by pushing it equally from both sides */
            margin-right: auto;
        }
        
        section {
            margin-bottom: 35px; 
        }

        @media (max-width: 600px) {
            .container {
                width: 95%; /* More width on smaller screens */
            }
            
            .video-container {
                flex: 0 0 100%; /* Each video takes full width on smaller screens */
            }
        }
  table {
    width: 100%; /* Adjust width as needed */
    border-collapse: collapse; 
  }

  td {
    width: 50%;  /* Each cell takes 50% of the table width */
    padding: 15px;
  }

  video {
    width: 100%; /* Make videos fill the cell  */
    max-height: 300px; /* Adjust maximum height if needed */
  }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="name">Mixture of Diffusion Timesteps for Multimodal Generation</h1>
        <h3 class="name">Anonymous submission to ICML'24</h3>
        <section>
        <div class="video-container">
            <video class="video" controls autoplay>
                <source src="AV-LDM_DEMO.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div>
        </section>
        <section>
            <h2>Abstract</h2>
            <p>We present a diffusion framework that can learn a wide range of conditional distributions within multimodal data using a single model. Our key contribution lies in how we parameterize the diffusion timestep in the forward diffusion process. Instead of the canonical fixed diffusion timestep, we propose applying variable timesteps across the temporal dimension and across modalities of the inputs. This formulation offers flexibility to introduce variable noise levels for various portions of the input by using a mixture of diffusion timesteps during training, enabling a single diffusion model to learn arbitrary conditional distributions. We implement this method for multimodal video generation by developing a transformer-based audiovisual latent diffusion model. Extensive experiments demonstrate that our approach can tackle a variety of crossmodal and multimodal interpolation tasks. In particular, our approach surpasses other baselines at generating samples that are temporally and perceptually consistent with the conditioning input.</p>
        </section>
        <section>
            <h2>Additional examples</h2>
            <a href="https://google.github.io/aistplusplus_dataset/">AIST++ Dataset</a>
            <div class="video-container">
                <video class="video" controls>
                    <source src="AIST.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
            <hr class="example-divider">
            <a href="https://opendatalab.com/OpenDataLab/High_Fidelity_Audio-Video_Landscape_Dataset">Landscape Dataset</a>
            <div class="video-container">
                <video class="video" controls>
                    <source src="Landscape.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </section>
    <section>
        <h2>Comparison with MM-Diffusion</h2>
        <p>We compare our proposed approach side by side to a few results from the AIST++ dataset for <a1 href="https://github.com/researchmm/MM-Diffusion/tree/main">MM-Diffusion</a1> (Ruan et. al, CVPR 2023) for various audiovisual generative tasks. </p>
        <p>N.B: We are comparing the generative video results at 128x128 resolution with super-resolution videos from MM-Diffusion</p>
        <h3><b>Audio-video continuation: Continue 2 seconds of AV given one frame</b></h3>
          <table>
    <tr>
      <td>
        <h3><b>Ours</b></h3>
      </td>
      <td>
        <h3><b>MM-Diffusion</b></h3>
      </td>
    </tr>
              <tr>
      <td>
        <video width="128" height="128" controls>
          <source src="AIST.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </td>
      <td>
        <video width="128" height="128" controls>
          <source src="Landscape.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </td>
    </tr>
  </table>


        <h3><b>Audio-to-Video: Generate Video given audio input</b></h3>
          <table>
                  <tr>
      <td>
        <h3><b>Ours</b></h3>
      </td>
      <td>
        <h3><b>MM-Diffusion</b></h3>
      </td>
    </tr>
    <tr>
      <td>
        <video width="128" height="128" controls>
          <source src="AIST.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </td>
      <td>
        <video width="128" height="128" controls>
          <source src="Landscape.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </td>
    </tr>
  </table>
        
    </section>
    </div>
</body>
</html>
